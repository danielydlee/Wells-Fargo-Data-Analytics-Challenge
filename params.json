{"name":"Wells Fargo Data Analytics Challenge","tagline":"Class Group Project for DATA101 @ CofC","body":"# Introduction to Wells Fargo Data Analytics Challenge\r\nDialogues on social media nowadays can provide tremendous insight into the behaviours, desires, pains, and thoughts of consumers. This project that our group worked on developed a repeatable process that identifies, classifies, and extracts the underlying drivers of consumer financial conversations and comments in social media data.\r\n\r\n## Question #1: What financial topics do consumers discuss on social media and what caused the consumers to post about this topic? \r\n\r\n### Approach and Methodology\r\nOur team was given the data set from August 2015, and Facebook comments between Aug. 2014 and Aug. 2015 regarding the chosen banks across the industry from the data file given, and first analyzed its vocabulary frequency, 3,000 counts being the least amount of frequency. This process helped us to understand the general comments that were being said about the bank industry, including the ones involving four main banks. We also approached these tweets and Facebook comments by excerpting those which only involve our four main banks. We first split the tweets and comments by Bank A, B, C, D, trying to grasp the level of negativeness and positiveness of each bank by using the sentiment scoring algorithm which would provide a score for each tweets and comments between -10 and 10 with 0 being neutral. The tweets and Facebook comments that were split at the previous stage contained all different kinds of topics that were not financially related. Therefore, we now wanted to pick out tweets and comments that only take financial terms into account among them to comprehend how positively or negatively each bank was perceived by customers. We then used the same sentiment scoring algorithm method again on those financial related tweets and comments to score each bank according to the score on each tweets and comments.\r\n\r\n### The Data and its Relationship to Social Conversation Drivers\r\nAccording to the data we have gathered from our approach and methodology, we could find several relationships between frequently used vocabulary and social conversation topics. Frequently used words such as “account”, “credit”, “finance”, “service” which will be thoroughly analyzed in the later stage of this report are great financially related indication of how the public perceives the bank industry or their specific bank on daily basis. The unconventional term like “GetCollegeReady”  that appears more than 3,000 times is also a great case of how these tweets and Facebook comments convey the social topic at the time. “GetCollegeReady” was one of four main banks’ subsidiary website with a purpose to better educate and engage students, parents, families, and high school counselors on best practices for planning and preparing for college. The site helps students understand how to pay for college, manage money, and build credit while in college taking into account a person’s full financial picture, including student loans, college credit cards, student checking and savings accounts, and student insurance. In an effort to amplify Get College Ready, the company leveraged a variety of its own social media channels and collaborate with nonprofit organizations using the hashtag #GetCollegeReady, which better explains why this term appeared on our dataset very frequently.  \r\n\r\n### Code\r\nBelow are the codes that were used during our approach and methodology to sort and analyze the given dataset of tweets and Facebook comments:\r\n\r\n1. banksort() reads the contents of a text file, scans for Bank A,B,C,D,\r\n\tand writes each entry to the appropriate output file.\r\n```P\r\ndef banksort():\r\n    \"\"\"\r\n    This function reads the contents of a text file, scans for BankA,B,C,D,\r\n    and writes the list item to the appropriate output\r\n    file. \r\n    \"\"\"\r\n    infileName = \"DataSet.txt\"\r\n    infile = open(infileName, \"rb\")\r\n    bankAoutfile = \"bankA.txt\"\r\n    bankBoutfile = \"bankB.txt\"\r\n    bankCoutfile = \"bankC.txt\"\r\n    bankDoutfile = \"bankD.txt\"\r\n    outfileA = open(bankAoutfile, \"w\")\r\n    outfileB = open(bankBoutfile, \"w\")\r\n    outfileC = open(bankCoutfile, \"w\")\r\n    outfileD = open(bankDoutfile, \"w\")    \r\n    for line in infile:\r\n        if b\"BankA\" in line:\r\n            print(line, file=outfileA)\r\n        elif b\"BankB\" in line:\r\n            print(line, file=outfileB)\r\n        elif b\"BankC\" in line:\r\n            print(line, file=outfileC)\r\n        elif b\"BankD\" in line:\r\n            print(line, file=outfileD)\r\n\r\n    infile.close()\r\n    outfileA.close()\r\n    outfileB.close()\r\n    outfileC.close()\r\n    outfileD.close()\r\n```\r\n2. accountsort() reads the contents of the sorted bank files (A,B,C,D), scans\r\n\tfor the word 'account' and writes to the appropriate output file.\r\n```P\r\ndef accountsort():\r\n    \"\"\"\r\n    This function reads the contents of the sorted bank files (A,B,C,D), scans\r\n    for the word 'account' and writes to the appropriate output file.\r\n    \"\"\"\r\n    infileA = open(\"bankA.txt\", \"rb\")\r\n    infileB = open(\"bankB.txt\", \"rb\")\r\n    infileC = open(\"bankC.txt\", \"rb\")\r\n    infileD = open(\"bankD.txt\", \"rb\")\r\n    accountoutA = open(\"accountA.txt\", \"w\")\r\n    accountoutB = open(\"accountB.txt\", \"w\")\r\n    accountoutC = open(\"accountC.txt\", \"w\")\r\n    accountoutD = open(\"accountD.txt\", \"w\")\r\n    for line in infileA:\r\n        if b\"account\" in line:\r\n            print(line, file=accountoutA)\r\n    for line in infileB:\r\n        if b\"account\" in line:\r\n            print(line, file=accountoutB)\r\n    for line in infileC:\r\n        if b\"account\" in line:\r\n            print(line, file=accountoutC)\r\n    for line in infileD:\r\n        if b\"account\" in line:\r\n            print(line, file=accountoutD)\r\n\r\n    infileA.close()\r\n    infileB.close()\r\n    infileC.close()\r\n    infileD.close()\r\n    accountoutA.close()\r\n    accountoutB.close()\r\n    accountoutC.close()\r\n    accountoutD.close()\r\n```\r\n\r\n3. score.sentiment() function uses laply() to iterate through the input text.\r\n           It strips punctuation and control characters from each line using R’s regular\r\n           expression-powered substitution function, gsub(), and uses match() against\r\n           each word list to find matches\r\n```R\r\nscore.sentiment = function(sentences, pos.words, neg.words, .progress='none')\r\n{\r\n  require(plyr)\r\n  require(stringr)\r\n  \r\n  # we got a vector of sentences. plyr will handle a list\r\n  # or a vector as an \"l\" for us\r\n  # we want a simple array of scores back, so we use\r\n  # \"l\" + \"a\" + \"ply\" = \"laply\":\r\n  scores = laply(sentences, function(sentence, pos.words, neg.words) {\r\n    \r\n    # clean up sentences with R's regex-driven global substitute, gsub():\r\n    sentence = gsub('[[:punct:]]', '', sentence)\r\n    sentence = gsub('[[:cntrl:]]', '', sentence)\r\n    sentence = gsub('\\\\d+', '', sentence)\r\n    # and convert to lower case:\r\n    sentence = tolower(sentence)\r\n    \r\n    # split into words. str_split is in the stringr package\r\n    word.list = str_split(sentence, '\\\\s+')\r\n    # sometimes a list() is one level of hierarchy too much\r\n    words = unlist(word.list)\r\n    \r\n    # compare our words to the dictionaries of positive & negative terms\r\n    pos.matches = match(words, pos.words)\r\n    neg.matches = match(words, neg.words)\r\n    \r\n    # match() returns the position of the matched term or NA\r\n    # we just want a TRUE/FALSE:\r\n    pos.matches = !is.na(pos.matches)\r\n    neg.matches = !is.na(neg.matches)\r\n    \r\n    # and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():\r\n    score = sum(pos.matches) - sum(neg.matches)\r\n    \r\n    return(score)\r\n  }, pos.words, neg.words, .progress=.progress )\r\n  \r\n  scores.df = data.frame(score=scores, text=sentences)\r\n  return(scores.df)\r\n}\r\n```\r\n\r\n\r\n## Question #2: Are the topics and “substance” consistent across the industry or are they isolated to individual banks? \r\n\r\n### List of Topics and Substance\r\nFirst, we took a closer look at the overall trends of the given banks: A, B, C, and D. \r\nStarting with over 200,000 unique data entries at our fingertips, we needed to trim the data, but still observe all banks simultaneously before we start comparing them individually. With the help of RStudio, we were able to determine the most critical words that occurred with over 3,000 frequencies. We included all banks in this test, and by using this as our initial test, we were able to pinpoint what specific words were used the most frequently about all banks.\r\nWe then could easily observe overarching trends within the data set before we even began conducting any further testing on individual banking. By only pinpointing key words occurring more than 3,000 times, we were able to not only observe, but draw a few conclusions on what some of the most common words and topics actually were throughout the past year of data. \r\n![](http://i.imgur.com/XNMxXfY.png?1)\r\n\r\n-Bank A's overall sentiment score\r\n![](http://i.imgur.com/KAmzr8G.png?1)\r\n\r\n-Bank A's sentiment score for the term 'account'\r\n![](http://i.imgur.com/ktryqNm.png?1)\r\n\r\n### Results and Insights\r\nThe overall sentiment levels for Banks A, B, C, D were fairly symmetrical, which was fairly surprising. We anticipated more variance within the sentiment levels of each of the banks, but, we came to find that all the banks in the overall sentiment level test were almost symmetric, or even a little skewed to the left. To our surprise, bank customers within the given data had an overall fair balance between positive and negative feedback via Facebook and Twitter. Bank D appeared to be the most symmetric of the banks in the overall sentiment level test comparison. But, there was not any drastic distinguishing jumps between the overall sentiment level comparisons worth noting. As aforementioned, although all banks appeared fairly symmetric, with a closer look, we saw there was a slight skewing to the left in all banks, but hardly enough to notice at first glance. This tells us that although all banks had quite a bit of both negative and positive feedback (fairly symmetric), the positive feedback won in the end by just nudge, which led the graphs to be slightly skewed left.\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}